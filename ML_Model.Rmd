---
title: "ML Model"
author: "Cohort B Team 3"
date: "3/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Library 
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(fastDummies)
library(caret)
library(MASS)
library(kernlab)
library(randomForest)
library(gbm)
```

# Load the dataset
```{r}
data <- read.csv("indeed_job_dataset.csv")
glimpse(data)
```

# Create a new working data called my data by removing some columns
```{r}
mydata <- data %>% dplyr::select(-X:-Link, -Skill, -Company, -Date_Since_Posted:-Location, -Company_Industry)
dim(mydata)
```

# EDA
```{r}
head(mydata)
summary(mydata)
```
* 3 main job types: analyst, engineer, scientist 
* No. of skills: Median - 7, Mean - 7.804, Range - 0 - 20
* 962 companies don't have any reviews/ ratings on Indeed
* Ineed does not have information on some companies revenue and number of employee information 

*Analysis on salary range*
```{r}
percentage <- prop.table(table(mydata$Queried_Salary)) * 100
cbind(freq=table(mydata$Queried_Salary), percentage=percentage)
```

```{r message=FALSE, warning=FALSE}
# Count of each salary range
ggplot(mydata) + 
  geom_histogram(aes(x = as.factor(Queried_Salary)),stat="count") + 
  theme_classic() + 
  labs(title = "Distribution of Estimated / Actual Salary Range of the Job Postings",
       x = "Salary Range", y = "Frequency")

# % of each salary range among the dataset 
mydata %>% 
  group_by(Queried_Salary) %>% 
  summarize(count=n()) %>% 
  mutate(perct = round(prop.table(count),2)*100) %>% 
  ggplot(aes(x = Queried_Salary, y = perct)) +
  geom_histogram(stat = "identity")+
  geom_text(aes(x=Queried_Salary, y=0.01, label= sprintf("%.2f%%", perct)),
            hjust=0.5, vjust=-3, size=4,
            color="white", fontface = "bold") +
  theme_classic() +
  labs(x = "Salary Range", y="Percentage (%)",
       title = "Estimated / Actual Salary Range of the Job Postings (%)")
```

*Other variables*
```{r message=FALSE, warning=FALSE}
# Count of each job type 
mydata %>% 
  group_by(Job_Type) %>% 
  summarize(count = n()) %>% 
  ggplot(aes(x = Job_Type, y = count)) + 
  geom_bar(stat = "identity") + 
  theme_classic() + 
  geom_text(aes(x = Job_Type, y = 1, label = count),
            hjust = 0.5, vjust = -3, size = 4,
            color = "white", fontface = "bold") +
  labs(title = "Distribution of Job Types", x = "Job Type", y="Count") 

## Multivariate Plots - look at the interactions between the variables
skills <- mydata[ ,8:17] 
skills %>% head()
featurePlot(x=skills, y=mydata$Queried_Salary, plot="box")
```

# Data Cleaning 
```{r}
summary(mydata) 
# shows that Company_Revenue & Company_Employees have blank values 

# fill those blank value with NA 
# Company_Revenue
mydata$Company_Revenue <- as.character(mydata$Company_Revenue)
mydata$Company_Revenue[mydata$Company_Revenue == ""] <- "NA"
mydata$Company_Revenue <- as.factor(mydata$Company_Revenue)
summary(mydata$Company_Revenue)

mydata$Company_Employees <- as.character(mydata$Company_Employees)
mydata$Company_Employees[mydata$Company_Employees == ""] <- "NA"
mydata$Company_Employees <- as.factor(mydata$Company_Employees)
summary(mydata$Company_Employees)

# replace NAs with o for No_of_Reviews & No_of_Stars
mydata[is.na(mydata)] <- 0

# Check if thereâ€™s any missing value in this dataset
sapply(mydata, function(x) sum(is.na(x)))

```

*Dummify the following columns *
```{r}
str(mydata) # check if the columns needed to be dumified are in factor forms 
mydata <-dummy_cols(mydata)

mydata <- mydata %>% dplyr::select(-Job_Type, -Company_Revenue, - Company_Revenue, - Company_Employees,
                            -"Queried_Salary_<80000": -"Queried_Salary_80000-99999" )
```

*Change colnames *
```{r}
colnames(mydata)
mydata <- mydata %>% rename_all(tolower)

colnames(mydata)[colnames(mydata) == "queried_salary"] <- "salary"
colnames(mydata)[colnames(mydata) == "others"] <- "other_skills"

colnames(mydata)[colnames(mydata) == "ca"] <- "california"
colnames(mydata)[colnames(mydata) == "ny"] <- "new_york"
colnames(mydata)[colnames(mydata) == "va"] <- "virginia"
colnames(mydata)[colnames(mydata) == "tx"] <- "texas"
colnames(mydata)[colnames(mydata) == "ma"] <- "massachusetts"
colnames(mydata)[colnames(mydata) == "il"] <- "illinois"
colnames(mydata)[colnames(mydata) == "wa"] <- "washington"
colnames(mydata)[colnames(mydata) == "md"] <- "maryland"
colnames(mydata)[colnames(mydata) == "dc"] <- "dc"
colnames(mydata)[colnames(mydata) == "nc"] <- "north_carolina"

colnames(mydata)[colnames(mydata) == "job_type_data_analyst"] <- "data_analyst"
colnames(mydata)[colnames(mydata) == "job_type_data_engineer"] <- "data_engineer"
colnames(mydata)[colnames(mydata) == "job_type_data_scientist"] <- "data_scientist"


colnames(mydata)[colnames(mydata) == "company_revenue_$1b to $5b (usd)"] <- "revenue_$1bto$5b"
colnames(mydata)[colnames(mydata) == "company_revenue_$5b to $10b (usd)"] <- "revenue_$5bto$10b"
colnames(mydata)[colnames(mydata) == "company_revenue_less than $1b (usd)"] <- "revenue<$1b"
colnames(mydata)[colnames(mydata) == "company_revenue_more than $10b (usd)"] <- "revenue>$10b"
colnames(mydata)[colnames(mydata) == "company_revenue_na"] <- "revenue_na"

colnames(mydata)[colnames(mydata) == "company_employees_10,000+"] <- "employees>10k"
colnames(mydata)[colnames(mydata) == "company_employees_less than 10,000"] <- "employees<10k"
colnames(mydata)[colnames(mydata) == "company_employees_na"] <- "employees_na"
colnames(mydata)

```

# Building machine learning models
*Split into the training and testing datasets*
```{r}
levels(mydata$salary)

# Determine sample size
set.seed(123456)

# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(mydata$salary, p=0.80, list=FALSE)
# select 20% of the data for validation
mydata_test <- mydata[-validation_index, ]
# use the remaining 80% of data to training and testing the models
mydata_train <- mydata[validation_index, ]

dim(mydata)
dim(mydata_train)
dim(mydata_test)
```

* Run algorithms using 10-fold cross validation
```{r}
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
```
Using the metric of "Accuracy" to evaluate machine learning models. This is a ratio of the number of correctly predicted instances in divided by the total number of instances in the dataset multiplied by 100 to give a percentage (e.g. 95% accurate). 

*Fit models*
a) Linear Discriminant Analysis (LDA)
```{r message=FALSE, warning=FALSE}
fit.lda <- train(salary~., data=mydata_train, method="lda", 
                 metric=metric, trControl=control)
```
b) StepwiseRegression
```{r message=FALSE}
# library(MASS)
fit.stepwise <- train(salary~., data=mydata_train, method="stepLDA", 
                      metric=metric, trControl=control)
```
c) k-Nearest Neighbors (kNN)
```{r}
fit.knn <- train(salary~., data=mydata_train, method="knn", 
                 metric=metric, trControl=control)
```
d) Support Vector Machines (SVM) with a linear kernel
```{r}
# library(kernlab)
# takes a long time! 
fit.svm <- train(salary~., data=mydata_train, method="svmRadial", 
                 metric=metric, trControl=control)
```
e) Random Forest (RF)
```{r}
# library(randomForest)
fit.rf <- train(salary~., data=mydata_train, method="rf",
                metric=metric, trControl=control)
```
f) boosted trees 
```{r}
# library(gbm)
fit.gbm <- train(salary~., data=mydata_train, method="gbm", 
                 metric=metric, trControl=control)
```

*Summarize accuracy of models*
```{r}
results <- resamples(list(lda=fit.lda, stepwise = fit.stepwise, knn=fit.knn, 
                          svm=fit.svm, rf=fit.rf, boosting=fit.gbm))
summary(results)
```
*Compare accuracy of models*
```{r}
dotplot(results)
```
As the grpah above shows, Random forest is the most arrucate. 

*Summary of the best model*
```{r}
print(fit.rf)
```

# Estimate the best model on testing dataset 
```{r}
predictions <- predict(fit.rf, mydata_test)
confusionMatrix(predictions, mydata_test$salary)
```

# Create prediction based on MSBA students 
```{r}
```


